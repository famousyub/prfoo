# -*- coding: utf-8 -*-
"""karray.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X1BOmVdEZAmLk3DlrKBOZVCrMx3FuOwo
"""

#importation des librairies
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.io import arff






#import data from csv
data=pd.read_csv("./content/newdata.csv",sep=";")



#visualiser les 5 premières lignes
data.head(5)

#supprimer les deux dernières colonnes
data = data.drop(["Unnamed: 13", "Unnamed: 14"], axis=1)

data.info()

data.columns

data1=data.copy()

"""---

### Analyse de la forme des données
"""

#ce sont des compteurs ,on peut les supprimer
data=data.drop(['ID_ministere','ID_mission','ID_missionnaire'],axis=1)

df2=data.copy()

df2.info()

"""⛳ Il est super utile de distinguer quelles sont les variables quantitatives et quelles sont les qualitatives."""

df2.dtypes.value_counts()

df2.dtypes.value_counts().plot.pie()

"""

Vérifions s'il existe des valeurs manquantes,
sachant que dans notre dataset elles sont marquées par "?", on va donc les affecter la valeur NAN puis les afficher:"""

for i in df2.columns:
  df2[i]=df2[i].replace('?',np.NAN)

df2.head(5)

df2

df2 = df2.drop(df2.index[125:])

df2

#Heatmap qui montre les valeurs manquantes
plt.figure(figsize=(10,5))
sns.heatmap(df2.isna(), cbar=True)

#Pourcentage des valeurs manquantes dans chaque colonne
((df2.isna().sum()/df2.shape[0])*100).sort_values(ascending=True)

df2.columns

# Convertir la colonne de date en format de date
df2['Date_Debut_reelle'] = pd.to_datetime(df2['Date_Debut_reelle'], format='%d/%m/%Y')

# Créer une nouvelle colonne pour représenter le nombre de jours dans l'année
df2['Date_Debut_reelle'] = df2['Date_Debut_reelle'].dt.dayofyear

df2['Date_Debut_prev'] = pd.to_datetime(df2['Date_Debut_prev'], format='%d/%m/%Y')

# Créer une nouvelle colonne pour représenter le nombre de jours dans l'année
df2['Date_Debut_prev'] = df2['Date_Debut_prev'].dt.dayofyear

df2['Date_fin_prev'] = pd.to_datetime(df2['Date_fin_prev'], format='%d/%m/%Y')

# Créer une nouvelle colonne pour représenter le nombre de jours dans l'année
df2['Date_fin_prev'] = df2['Date_fin_prev'].dt.dayofyear

df2['Date_fin_reelle'] = pd.to_datetime(df2['Date_fin_reelle'], format='%d/%m/%Y')

# Créer une nouvelle colonne pour représenter le nombre de jours dans l'année
df2['Date_fin_reelle'] = df2['Date_fin_reelle'].dt.dayofyear

df2.head(5)

df2.head(5)

# Supposons que votre dataframe s'appelle df2
df2['tauxRetard'] = df2['tauxRetard'].str.replace(',', '.').astype(float)

df2.dtypes.value_counts()

"""### Examen de la colonne target:

"""

#prepare variables for feature selection
y = df2['tauxRetard']
X = df2.loc[:, df2.columns != 'tauxRetard']

# X = X.apply(pd.to_numeric, errors='coerce')
# y = y.apply(pd.to_numeric, errors='coerce')

data1 = data1.drop(data1.index[125:])






# Feature Importance:
# from sklearn.ensemble import ExtraTreesClassifier
# model=ExtraTreesClassifier()
# model.fit(X,y)

# plt.figure(figsize=(8,6))
# ranked_features=pd.Series(model.feature_importances_,index=X.columns)
# ranked_features.nlargest(24).plot(kind='barh')
# plt.show()

# #Geting the 5 importante features
# imp_features=list(ranked_features.nlargest(5).index)
# print(imp_features)

X = df2.loc[:, ['ecart_delai', 'Duree_prev', 'Duree_reelle', 'frais_transport', 'Date_fin_reelle']]
y = df2['tauxRetard']

"""# Modelisation"""

import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split,GridSearchCV
import matplotlib.pyplot as plt
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.preprocessing import PowerTransformer
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn import metrics
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import r2_score

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error

#Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

df2['tauxRetard']

y_train

model = GradientBoostingRegressor()

# Entraîner le modèle
model.fit(X_train, y_train)

# Faire des prédictions sur l'ensemble de test
y_pred = model.predict(X_test)

# Évaluer les performances du modèle en utilisant la métrique d'erreur quadratique moyenne (MSE)
mse1 = mean_squared_error(y_test, y_pred)
r1 = r2_score(y_test, y_pred)
print("Mean Squared Error:", mse1)
print("Coefficient de détermination (R-squared)",r1)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Initialiser le modèle de Forêts aléatoires
model = RandomForestRegressor()

# Entraîner le modèle
model.fit(X_train, y_train)

# Faire des prédictions sur l'ensemble de test
y_pred = model.predict(X_test)

# Évaluer les performances du modèle en utilisant la métrique d'erreur quadratique moyenne (MSE)
mse2 = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse2)
print("Coefficient de détermination (R-squared)",r2)

from sklearn.tree import DecisionTreeRegressor

# Initialiser le modèle de l'arbre de décision
model = DecisionTreeRegressor()

# Entraîner le modèle
model.fit(X_train, y_train)

# Faire des prédictions sur l'ensemble de test
y_pred = model.predict(X_test)

# Évaluer les performances du modèle en utilisant la métrique d'erreur quadratique moyenne (MSE)
mse3 = mean_squared_error(y_test, y_pred)
r3 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse3)
print("Coefficient de détermination (R-squared)",r3)

from sklearn.linear_model import LinearRegression
model = LinearRegression()

# Entraîner le modèle
model.fit(X_train, y_train)

# Faire des prédictions sur l'ensemble de test
y_pred = model.predict(X_test)

# Évaluer les performances du modèle en utilisant la métrique d'erreur quadratique moyenne (MSE)
mse4 = mean_squared_error(y_test, y_pred)
r4 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse4)
print("Coefficient de détermination (R-squared)",r4)

# Préparer les caractéristiques pour une prédiction
nouvelles_caracteristiques = [[2.5, 10, 8, 100, 20]]

# Effectuer la prédiction
prediction = model.predict(nouvelles_caracteristiques)

# Afficher la prédiction
print("La prédiction du taux de retard est :", prediction)



from flask import Flask , render_template ,jsonify,Response
import json
import io
from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
from matplotlib.figure import Figure


from flask_cors  import CORS
from datetime import datetime

app = Flask(__name__)

CORS(app)
cors = CORS(app, resource={
    r"/*":{
        "origins":"*"
    }
})




@app.route("/plt",methods=["GET"])
def draw():
  fig = Figure()
  axis = fig.add_subplot(1, 1, 1)

  axis.plot(X, y)
  df2.dtypes.value_counts().plot.pie()
  output = io.BytesIO()
  FigureCanvas(fig).print_png(output)
  return Response(output.getvalue(), mimetype='image/png')
from flask import url_for







import matplotlib.pyplot as plt
import os
import numpy as np
import matplotlib
from project.project import home
matplotlib.use('Agg')
  
  
# Flask constructor
app = Flask(__name__)



# Generate a scatter plot and returns the figure
def get_plot():
  
    data = {
        'a': X,
        'b': X ,
     
    }
  
    #data['b'] = data['a'] + 10 * np.random.randn(50)
    #data['d'] = np.abs(data['d']) * 100
  
    plt.scatter('a', 'b', data=data)
    plt.xlabel('X label')
    plt.ylabel('Y label')
  
    return plt
  
# Root URL
@app.get('/img')
def single_converter():
    # Get the matplotlib plot
    plot = get_plot()
  
    # Save the figure in the static directory
    plot.savefig(os.path.join('static', 'images', 'plot.png'))
  
    # Close the figure to avoid overwriting
    plot.close()
    return render_template('test1.html')


from flask_cors  import CORS
from datetime import datetime

app = Flask(__name__)

CORS(app)
cors = CORS(app, resource={
    r"/*":{
        "origins":"http://localhost:4200"
    }
})



@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE')
    return response
@app.route("/val/<val1>/val2/<val2>/val3/<val3>/val4/<val4>/val5/<val5>",methods=["GET"])
def index(val1, val2,val3,val4,val5):
  from sklearn.linear_model import LinearRegression
  model = LinearRegression()

  # Entraîner le modèle
  model.fit(X_train, y_train)

  # Faire des prédictions sur l'ensemble de test
  y_pred = model.predict(X_test)

  # Évaluer les performances du modèle en utilisant la métrique d'erreur quadratique moyenne (MSE)
  mse4 = mean_squared_error(y_test, y_pred)
  r4 = r2_score(y_test, y_pred)

  print("Mean Squared Error:", mse4)
  print("Coefficient de détermination (R-squared)",r4)

  # Préparer les caractéristiques pour une prédiction
  #nouvelles_caracteristiques = [[2.5, 10, 8, 100, 20]]

  # Effectuer la prédiction
  prediction = model.predict([[float(val1),float(val2),float(val3),float(val4),float(val5)]])
  print(prediction)
  with open("resultat.txt","a+") as f :
    f.write(json.dumps(list(prediction)[0]))
    f.write("\n\n\t")

  r = list(prediction)[0]
  # Afficher la prédiction
  return  jsonify({"response":r})



app.register_blueprint (home)




if __name__ =='__main__':
  app.run(port= 5000, host ="localhost")











